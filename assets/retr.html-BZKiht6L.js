import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as n,o as i,c as m,a as s,d as a,b as p,e as l}from"./app-SD3SAAIy.js";const c="/assets/images/rcmd/ch2.1/Snipaste_2024-06-07_16-56-25.png",r={},h=l('<h2 id="主流召回方法简介" tabindex="-1"><a class="header-anchor" href="#主流召回方法简介"><span>主流召回方法简介</span></a></h2><p>目前市场上所有的召回方法都可以归纳为3大类：</p><figure><img src="'+c+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="基于规则的召回" tabindex="-1"><a class="header-anchor" href="#基于规则的召回"><span>基于规则的召回</span></a></h3><p>基于规则是最常用的召回策略，也是解释性最强的召回策略。常见的规则召回策略有：基于内容标签的召回，基于商品销量或者内容热度的召回，召回历史高点击率的物料，召回平台评价&amp;质量分比较高的物料，召回用户经常购买的一些商品或者常看的物料；</p><p>主要方法：</p><ul><li>标签召回：推荐算法1.0时代都是基于内容的推荐，而基于内容的推荐基本上都是通过标签相似度来进行推荐。尤其是在电影&amp;音乐网站上。比如你看过标签为“武侠”、“爱情”的电影，系统会基于这个标签给你召回相同标签的物料。</li><li>热销召回：热销召回在电商领域比较多，基于商品的销量召回一些大家都比较喜欢，销量高的商品。这种召回策略应对冷启用户特别好用。同时扩展到内容领域逻辑也是一样，只是这里的“热销”可以换成“热度”。把销量的因素换成比如观看次数等等。</li><li>高点击率商品召回：推荐系统核心还是要不断提升场景里面的点击率，所以我们在召回时就需要有专门的路去召回那些历史物料中点击率比较高的商品。当然这一路需要和其他路进行融合，不然会造成非常强的马太效应。</li><li>高质量分的物料：此类物料是最适合用于冷启，在电商领域当一个新的用户访问系统不知道为他推荐什么商品时，我们可以为他推荐历史评价、销量、收藏、点赞等都反响比较好的商品。</li><li>复购的物料：这一路在生鲜电商里面经常用，很多用户每天买的蔬菜肉类都比较相似，所以推荐系统会专门有一路召回为用户推荐他历史购买过的商品。但是复购这一路召回在综合性电商里基本不用，比如淘宝&amp;京东，这一类物品用户会主动搜索。</li></ul><p>基于规则的召回主要优缺点：</p><ul><li>优点：策略逻辑清晰明了，业务意义明确，可解释性极强；</li><li>缺点：个性化弱，千人一面，为每个用户推荐的商品比较类似。同时容易引起马太效应，头部的物料得到越来越多的曝光机会，尾部的物料曝光机会越来越少。</li></ul><h4 id="规则召回主要链路" tabindex="-1"><a class="header-anchor" href="#规则召回主要链路"><span>规则召回主要链路</span></a></h4><ul><li>相似性： <ul><li>用户观看、评论、关注、点赞、打赏、搜索过的主播的相似主播</li><li>重定向召回，用户长播、点赞、打赏过的主播</li><li>根据打赏主播图召回相似的主播</li><li>关注的主播</li></ul></li><li>兴趣： <ul><li>双塔召回，使用用户短视频兴趣特征训练</li><li>挖掘用户观看主播所属tag，召回tag下优质主播</li><li>兴趣领域垂类召回：游戏、美食、旅游等</li></ul></li><li>距离： <ul><li>距离召回，附近的主播，同省、同城主播召回</li><li>家乡召回，用户家乡定位附近开播的主播</li></ul></li><li>策略： <ul><li>正在PK的主播召回</li><li>颜值主播召回、明星召回</li><li>对新用户友好的召回，内容为影视类</li><li>基于人工标注的召回：唱歌、跳舞等</li></ul></li><li>优质、热度： <ul><li>召回全局优质主播</li><li>南北高热主播，由数据挖掘组提供</li><li>高光时刻奇异点召回、小时榜召回</li><li>大额用户打赏召回、大额打赏PK主播召回</li></ul></li><li>关系： <ul><li>一跳关系链召回，正在开播的好友</li><li>二跳关系链召回，好友爱看的直播</li></ul></li><li>冷启动： <ul><li>随机冷启召回、距离冷启召回、属性冷启召回</li></ul></li></ul><h3 id="协同过滤" tabindex="-1"><a class="header-anchor" href="#协同过滤"><span>协同过滤</span></a></h3><p>协同过滤的召回算法可以说是推荐系统最经典的算法了，甚至可以说有了协同过滤算法才真正代表了推荐系统的诞生。协同过滤算法最经典的是以下两个算法：</p><ul><li>I2I（Item-CF）：用户A喜欢的物料a，为用户A推荐和物料a比较相似的物料b；该算法的核心问题是如何计算物料a和其他物料b,c,d,e......的相似度；该算法最早起源于电商巨头亚马逊；</li><li>U2U（User-CF）：用户A和用户B很相似，为用户A推荐用户B感兴趣且用户A之前没有接触过的物料a，因为二者是相似的，所以我们认为用户B感兴趣的物料用户A也会感兴趣；该算法的核心是如何计算用户与用户之间的相似度；</li></ul><p>协同过滤的主要优缺点：</p><ul><li>优点：算法逻辑相对比较简单容易实现，但同时又有不错的效果，具备了一定的个性化。</li><li>缺点：和基于规则的召回具有同样的问题，冷启动的问题比较明显，同时同样会存在一定的马太效应，头部热门商品更容易和其他商品产生更多关联。但是整体协同过滤算法的出现已经让推荐系统进步了一大截；协同过滤算法下一篇文章将详细展开介绍。</li></ul><h3 id="基于向量的召回" tabindex="-1"><a class="header-anchor" href="#基于向量的召回"><span>基于向量的召回</span></a></h3><p>其实无论是基于规则的召回，还是协同过滤算法。我们都是通过一定规则或者方法去计算物料与物料之间的相似度，用户与用户之间的相似度。协同过滤算法里面更多是一种基于统计维度的，而随着算法进步我们引入一种新的思想。基于向量去计算相似度。</p><ul><li>FM：Factor Machine-因子分解机，是在2010年由谷歌推荐系统的大佬Steffen Rendle提出的。核心思想是通过对两两特征组合，引入交叉项特征；其次是通过引入隐向量（对参数矩阵进行矩阵分解），降低模型的高维灾难，完成对特征的参数估计；</li><li>DSSM：Deep Structured Semantic Models，深度语义匹配模型，微软于2016年提出，又叫“双塔模型”。分别构建用户的user embedding和物料的item embedding，所以称为双塔。核心思想还是通过Embedding分别去表达User和Item的特征，然后再计算相似度。 此种策略的优缺点</li></ul><p>基于向量的召回主要优缺点：</p><ul><li>优点：特征理解更加深刻，模型效果更优。</li><li>缺点：模型可解释性差。</li></ul><h2 id="召回算法训练" tabindex="-1"><a class="header-anchor" href="#召回算法训练"><span>召回算法训练</span></a></h2><h3 id="负样本的选择" tabindex="-1"><a class="header-anchor" href="#负样本的选择"><span>负样本的选择</span></a></h3><p>注意，不能使用有曝光但没有点击的样本作为负样本！不能使用有曝光但没有点击的样本作为负样本！不能使用有曝光但没有点击的样本作为负样本！</p><p>因为召回的目的是区分用户不感兴趣的物品和感兴趣的物品，而区分比较感兴趣还是非常感兴趣那是后续粗排、精排的任务，所以曝光就代表后续的粗排、精排模型已经认为这个样本用户是感兴趣的，曝光但未点击只是因为存在用户更感兴趣的物品，而不是未点击的就不感兴趣。这些曝光但未点击的样本是用来训练排序模型的。</p><p>那么如何选择负样本呢？</p><h4 id="没有被召回的物品-简单负样本" tabindex="-1"><a class="header-anchor" href="#没有被召回的物品-简单负样本"><span><strong>没有被召回的物品（简单负样本）</strong></span></a></h4><p>由于几亿个物品只有几千个物品被召回，也就是说未被召回的物品约等于全体物品，所以直接从全体物品中抽样即可。</p><p>但是要注意，如何抽样也需要考虑，由于二八法则，冷门物品占大多数，而因为正样本通常是热门物品，随机抽样的话，负样本则大多是冷门物品，这会使得热门物品更热，冷门物品更冷。</p>',29),o=s("p",null,[a("第一种方法：使用打压热门物品的非均匀抽样：使负样本抽样概率与热门程度（点击次数）正相关。通常使用"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mtext",null,"抽样概率"),s("mo",null,"∝"),s("msup",null,[s("mtext",null,"点击次数"),s("mn",null,"0.75")])]),s("annotation",{encoding:"application/x-tex"},"\\text{抽样概率} \\propto \\text{点击次数}^{0.75}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord text"},[s("span",{class:"mord cjk_fallback"},"抽样概率")]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∝"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8873em"}}),s("span",{class:"mord"},[s("span",{class:"mord text"},[s("span",{class:"mord cjk_fallback"},"点击次数")]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8873em"}},[s("span",{style:{top:"-3.1362em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"0.75")])])])])])])])])])])]),a("。0.75是个经验值。")],-1),u=s("p",null,"第二种方法：batch内负样本，一个batch会有很多个用户物品对，每个用户都可以和其他用户对应的物品组成负样本对。",-1),d=s("ul",null,[s("li",null,"但是这样存在一个问题，一个物品出现在batch内的概率次数会正比于点击次数，物品成为负样本的概率本该是正比于点击次数的0.75次方，但是在这里是正比于1次方，也就是说，打压热门物品程度过高了。"),s("li",null,[a("纠偏方法：（根据youtube和小红书的经验）假设物品"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"i")]),s("annotation",{encoding:"application/x-tex"},"i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6595em"}}),s("span",{class:"mord mathnormal"},"i")])])]),a("被抽样到的概率"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"p"),s("mi",null,"i")]),s("mo",null,"∝"),s("mtext",null,"点击次数")]),s("annotation",{encoding:"application/x-tex"},"p_i \\propto \\text{点击次数}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"p"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"∝"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord text"},[s("span",{class:"mord cjk_fallback"},"点击次数")])])])]),a("，预估用户对物品"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"i")]),s("annotation",{encoding:"application/x-tex"},"i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6595em"}}),s("span",{class:"mord mathnormal"},"i")])])]),a("的兴趣为"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"c"),s("mi",null,"o"),s("mi",null,"s"),s("mo",{stretchy:"false"},"("),s("mi",null,"a"),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"b"),s("mi",null,"i")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"cos(a,b_i)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"cos"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])]),a("，在训练时，我们将其调整为"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"c"),s("mi",null,"o"),s("mi",null,"s"),s("mo",{stretchy:"false"},"("),s("mi",null,"a"),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"b"),s("mi",null,"i")]),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mi",null,"l"),s("mi",null,"o"),s("mi",null,"g"),s("msub",null,[s("mi",null,"p"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"cos(a,b_i)-logp_i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"cos"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"p"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("，而在线上部署时则不做改动。")])],-1),g=l('<h4 id="被排序淘汰的物品-困难负样本" tabindex="-1"><a class="header-anchor" href="#被排序淘汰的物品-困难负样本"><span><strong>被排序淘汰的物品（困难负样本）</strong></span></a></h4><p>即没有通过粗排或在精排中排序靠后被截断了的物品，这说明这些物品用户可能存在兴趣，但是兴趣比较弱。</p><p>最后，训练召回模型常用的负样本是混合几种负样本，常用50%全体物品+50%没通过排序的物品。</p><h2 id="召回算法评估" tabindex="-1"><a class="header-anchor" href="#召回算法评估"><span>召回算法评估</span></a></h2><p>预测评分的推荐系统，如Netfix，打星 / 评分:</p><ul><li>RMSE（均方根误差）</li></ul><p>基于模型召回：</p><ul><li>Precision &amp; Recall</li><li>MAP</li><li>Hit Rate</li></ul><p>基于规则召回：</p><ul><li>不能评估</li></ul><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h2>',11),x={href:"https://zhuanlan.zhihu.com/p/524617291",target:"_blank",rel:"noopener noreferrer"};function b(v,y){const t=n("ExternalLinkIcon");return i(),m("div",null,[h,o,u,d,g,s("p",null,[a("推荐策略产品经理必读系列—第三讲推荐系统的召回"),s("a",x,[a("https://zhuanlan.zhihu.com/p/524617291"),p(t)])])])}const k=e(r,[["render",b],["__file","retr.html.vue"]]),w=JSON.parse('{"path":"/rcmd/ch02/retr.html","title":"召回算法基本信息","lang":"zh-CN","frontmatter":{"date":"2024-06-13T00:00:00.000Z","title":"召回算法基本信息","author":"Genhiy","order":1,"category":["推荐系统"],"tag":["无标签"],"feed":false,"seo":false,"head":[]},"headers":[{"level":2,"title":"主流召回方法简介","slug":"主流召回方法简介","link":"#主流召回方法简介","children":[{"level":3,"title":"基于规则的召回","slug":"基于规则的召回","link":"#基于规则的召回","children":[]},{"level":3,"title":"协同过滤","slug":"协同过滤","link":"#协同过滤","children":[]},{"level":3,"title":"基于向量的召回","slug":"基于向量的召回","link":"#基于向量的召回","children":[]}]},{"level":2,"title":"召回算法训练","slug":"召回算法训练","link":"#召回算法训练","children":[{"level":3,"title":"负样本的选择","slug":"负样本的选择","link":"#负样本的选择","children":[]}]},{"level":2,"title":"召回算法评估","slug":"召回算法评估","link":"#召回算法评估","children":[]},{"level":2,"title":"参考资料","slug":"参考资料","link":"#参考资料","children":[]}],"git":{},"readingTime":{"minutes":8.51,"words":2554},"filePathRelative":"rcmd/ch02/retr.md","localizedDate":"2024年6月13日"}');export{k as comp,w as data};
