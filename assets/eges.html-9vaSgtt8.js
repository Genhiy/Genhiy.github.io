import{_ as p}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as l,o,c as i,a as s,d as n,b as t,e}from"./app-SD3SAAIy.js";const c={},u=e('<p>Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba：这篇论文是阿里巴巴在18年发表于KDD的关于召回阶段的工作。该论文提出的方法是在基于图嵌入的方法上，通过引入side information来解决实际问题中的数据稀疏和冷启动问题。</p><h2 id="动机" tabindex="-1"><a class="header-anchor" href="#动机"><span>动机</span></a></h2><p>在电商领域，推荐已经是不可或缺的一部分，旨在为用户的喜好提供有趣的物品，并且成为淘宝和阿里巴巴收入的重要引擎。尽管学术界和产业界的各种推荐方法都取得了成功，如协同过滤、基于内容的方法和基于深度学习的方法，但由于用户和项目的数十亿规模，传统的方法已经不能满足于实际的需求，主要的问题体现在三个方面：</p><ul><li>可扩展性：现有的推荐方法无法扩展到在拥有十亿的用户和二十亿商品的淘宝中。</li><li>稀疏性：存在大量的物品与用户的交互行为稀疏。即用户的交互到多集中于以下部分商品，存在大量商品很少被用户交互。</li><li>冷启动：在淘宝中，每分钟会上传很多新的商品，由于这些商品没有用户行为的信息（点击、购买等），无法进行很好的预测。</li></ul><p>针对于这三个方面的问题， 本文设计了一个两阶段的推荐框架：<strong>召回阶段和排序阶段</strong>，这也是推荐领域最常见的模型架构。而本文提及的EGES模型主要是解决了匹配阶段的问题，通过用户行为计算商品间两两的相似性，然后根基相似性选出topK的商品输入到排序阶段。</p><p>为了学习更好的商品向量表示，本文通过用户的行为历史中构造一个item-item 图，然后应用随机游走方法在item-item 图为每个item获取到一个序列，然后通过Skip-Gram的方式为每个item学习embedding(这里的item序列类似于语句，其中每个item类比于句子中每个word)，这种方式被称为图嵌入方法(Graph Embedding)。文中提出三个具体模型来学习更好的物品embedding，更好的服务于召回阶段。</p><h2 id="思路" tabindex="-1"><a class="header-anchor" href="#思路"><span>思路</span></a></h2><p>根据上述所面临的三个问题，本文针对性的提出了三个模型予以解决：Base Graph Embedding（BGE）；Graph Embedding with Side Information（GES）；Enhanced Graph Embedding with Side Information（EGES）。</p><p>考虑可扩展性的问题，图嵌入的随机游走方式可以在物品图上捕获<strong>物品之间高阶相似性</strong>，即Base Graph Embedding（BGE）方法。其不同于CF方法，除了考虑物品的共现，还考虑到了行为的序列信息。</p><p>考虑到稀疏性和冷启物品问题，在图嵌入的基础上，考虑了节点的属性信息。希望具有相似属性的物品可以在空间上相似，即希望通过头部物品，提高属性信息的泛化能力，进而帮助尾部和冷启物品获取更加准确的embedding，即Graph Embedding with Side Information（GES）方法。</p><p>考虑到不同属性信息对于学习embedding的贡献不同，因此在聚合不同的属性信息时，动态的学习不同属性对于学习节点的embedding所参与的重要性权重，即Enhanced Graph Embedding with Side Information（EGES）。</p><h2 id="模型结构与原理" tabindex="-1"><a class="header-anchor" href="#模型结构与原理"><span>模型结构与原理</span></a></h2>',12),r=s("p",null,[n("文中所提出的方法是基于经典的图嵌入模型DeepWalk进行改进，其目标是通过物品图G，学习一个映射函数"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"f"),s("mo",null,":"),s("mi",null,"V"),s("mo",null,"−"),s("mo",null,">"),s("msup",null,[s("mi",null,"R"),s("mi",null,"d")])]),s("annotation",{encoding:"application/x-tex"},"f:V -> R^d")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},":"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mord"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},">"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8491em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8491em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"d")])])])])])])])])])]),n(" ，将图上节点映射成一个embedding。具体的步骤包括两步：1.通过随机游走为图上每个物品生成序列；2.通过Skip-Gram算法学习每个物品的embedding。因此对于该方法优化的目标是，在给定的上下文物品的前提下，最大化物品v的条件概率，即物品v对于一个序列里面的其他物品要尽可能的相似。接下来看一些每个模型具体内容。")],-1),m=e('<h3 id="构建物品图" tabindex="-1"><a class="header-anchor" href="#构建物品图"><span>构建物品图</span></a></h3><p>在介绍三个模型之前，我们首先需要构建好item-item图。由于基于CF的方法仅考虑物品之间的共现，忽略了行为的序列信息(即序列中相邻的物品之间的语义信息)，因此item-item图的构建方式如下图所示。</p><div align="center"><img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328133138263.png" style="zoom:80%;"></div><p>首先根据用户的session行为序列构建网络结构，即序列中相邻两个item之间在存在边，并且是有向带权图。物品图边上的权重为所有用户行为序列中两个 item 共现的次数，最终构造出来简单的有向有权图。</p><p>值得注意的是，本文通过行为序列中物品的共现来表示其中的<strong>语义信息</strong>，并将这种语义信息理解为<strong>物品之间的相似性</strong>，并将共现频次作为相似性的一个度量值。其次基于用户的历史行为序列数据，一般不太可能取全量的历史序列数据，一方面行为数据量过大，一方面用户的兴趣会随时间发生演变，因此在处理行为序列时会设置了一个窗口来截断历史序列数据，切分出来的序列称为session。</p><p>由于实际中会存在一些现实因素，数据中会有一些噪音，需要特殊处理，主要分为三个方面：</p><ul><li>从行为方面考虑，用户在点击后停留的时间少于1秒，可以认为是误点，需要移除。</li><li>从用户方面考虑，淘宝场景中会有一些过度活跃用户。本文对活跃用户的定义是三月内购买商品数超过1000，或者点击数超过3500，就可以认为是一个无效用户，需要去除。</li><li>从商品方面考虑，存在一些商品频繁的修改，即ID对应的商品频繁更新，这使得这个ID可能变成一个完全不同的商品，这就需要移除与这个ID相关的这个商品。</li></ul><p>在构建完item-item图之后，接下来看看三个模型的具体内容。</p><h3 id="图嵌入-bge" tabindex="-1"><a class="header-anchor" href="#图嵌入-bge"><span>图嵌入(BGE)</span></a></h3><p>对于图嵌入模型，第一步先进行随机游走得到物品序列；第二部通过skip-gram为图上节点生成embedding。那么对于随机游走的思想：如何利用随机游走在图中生成的序列？不同于DeepWalk中的随机游走，本文的采样策略使用的是带权游走策略，不同权重的游走到的概率不同，（其本质上就是node2vec），传统的node2vec方法可以直接支持有向带权图。因此在给定图的邻接矩阵M后(表示节点之间的边权重)，随机游走中每次转移的概率为：</p><div align="center"><img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328144516898.png" style="zoom:80%;"></div>',11),k=s("p",null,[n("其中"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"M"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"j")])])]),s("annotation",{encoding:"application/x-tex"},"M_{ij}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9694em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"M"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.109em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"ij")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])])])])]),n("为边"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"e"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"j")])])]),s("annotation",{encoding:"application/x-tex"},"e_{ij}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"ij")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])])])])]),n("上的权重，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"N"),s("mo",{lspace:"0em",rspace:"0em"},"+")]),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"v"),s("mi",null,"i")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"N_{+}(v_i)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2583em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.109em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"+")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])]),n("表示节点"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"v"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"v_i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n("所有邻居节点集合，并且随机游走的转移概率的对每个节点所有邻接边权重的归一化结果。在随即游走之后，每个item得到一个序列，如下图所示：")],-1),d=e('<div align="center"><img src="https://cdn.jsdelivr.net/gh/swallown1/blogimages@main/images/image-20220418142135912.png" style="zoom:47%;"></div><p>然后类似于word2vec，为每个item学习embedding，于是优化目标如下：</p><div align="center"><img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328144931957.png" style="zoom:77%;"></div><p>其中，w 为窗口大小。考虑独立性假设的话，上面的式子可以进一步化简：</p><div align="center"><img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328145101109.png" style="zoom:77%;"></div><p>这样看起来就很直观了，在已知物品 i 时，最大化序列中(上下文)其他物品 j 的条件概率。为了近似计算，采样了Negative sampling，上面的优化目标可以化简得到如下式子：</p><div align="center"><img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328145318718.png" style="zoom:80%;"></div>',7),v=s("p",null,[n("其中"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"N"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"v"),s("mi",null,"i")]),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")])]),s("annotation",{encoding:"application/x-tex"},"N(v_i)'")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0019em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])])])])]),n("表示负样本集合，负采样个数越多，结果越好。")],-1),g=s("h3",{id:"基于side-information的图嵌入-ges",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#基于side-information的图嵌入-ges"},[s("span",null,"基于side information的图嵌入（GES）")])],-1),h=s("p",null,"尽管BGE将行为序列关系编码进物品的embedding中，从而从用户行为中捕捉高阶相似性。但是这里有个问题，对于新加入的商品，由于未和用户产生过交互，所以不会出现在item-item图上，进而模型无法学习到其embedding，即无法解决冷启动问题。",-1),b=s("p",null,[n("为了解决冷启问题，本文通过使用side information（ 类别，店铺, 价格等）加入模型的训练过程中，使得模型最终的泛化能力体现在商品的side information上。这样通过"),s("strong",null,"side information学习到的embedding来表示具体的商品"),n("，使得相似side information的物品可以得到在空间上相近的表示，进而来增强 BGE。")],-1),_=s("p",null,[n("那么对于每个商品如何通过side information的embedidng来表示呢？对于随机游走之后得到的商品序列，其中每个每个商品由其id和属性(品牌，价格等)组成。用公式表示，对于序列中的每一个物品可以得到"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"W"),s("mi",null,"V"),s("mn",null,"0")]),s("mo",{separator:"true"},","),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("msubsup",null,[s("mi",null,"W"),s("mi",null,"V"),s("mi",null,"n")])]),s("annotation",{encoding:"application/x-tex"},"W^0_V,...W_V^n")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0894em","vertical-align":"-0.2753em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-2.4247em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.22222em"}},"V")])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2753em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"..."),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6644em"}},[s("span",{style:{top:"-2.4247em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.22222em"}},"V")])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2753em"}},[s("span")])])])])])])])]),n(",（n+1）个向量表示，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"W"),s("mi",null,"V"),s("mn",null,"0")])]),s("annotation",{encoding:"application/x-tex"},"W^0_V")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0894em","vertical-align":"-0.2753em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-2.4247em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.22222em"}},"V")])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2753em"}},[s("span")])])])])])])])]),n("表示物品v，剩下是side information的embedding。然后将所有的side information聚合成一个整体来表示物品，聚合方式如下：")],-1),y=s("p",null,"​ $$H_v = \\frac{1}{n+1}\\sum_{s=0}^n W^s_v$$",-1),f=s("p",null,[n("其中，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mi",null,"v")])]),s("annotation",{encoding:"application/x-tex"},"H_v")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"v")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n("是商品 v 的聚合后的 embedding 向量。")],-1),w=s("h3",{id:"增强型egs-eges",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#增强型egs-eges"},[s("span",null,"增强型EGS（EGES）")])],-1),x=s("p",null,"尽管 GES 相比 BGE 在性能上有了提升，但是在聚合多个属性向量得到商品的embedding的过程中，不同 side information的聚合依然存在问题。在GES中采用 average-pooling 是在假设不同种类的 side information 对商品embedding的贡献是相等的，但实际中却并非如此。例如，购买 Iphone 的用户更可能倾向于 Macbook 或者 Ipad，相比于价格属性，品牌属性相对于苹果类商品具有更重要的影响。因此，根据实际现状，不同类型的 side information 对商品的表示是具有不同的贡献值的。",-1),z=s("p",null,"针对上述问题，作者提出了weight pooling方法来聚合不同类型的 side information。具体地，EGES 与 GES 的区别在聚合不同类型 side information计算不同的权重，根据权重聚合 side information 得到商品的embedding，如下图所示：",-1),E=s("div",{align:"center"},[s("img",{src:"http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328154950289.png",style:{zoom:"80%"}})],-1),G=s("p",null,[n("其中 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"a"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"a_i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n(" 表示每个side information 用于计算权重的参数向量，最终通过下面的公式得到商品的embedding：")],-1),M=s("p",null,[n("​ $$H_v = \\frac{\\sum_{j=0}^n e"),s("sup",null,"{a_v"),n("j} W_v"),s("sup",null,"j}{\\sum_{j=0}"),n("n e"),s("sup",null,"{a_v"),n("j}}$$")],-1),S=s("p",null,[n("这里对参数 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"a"),s("mi",null,"v"),s("mi",null,"j")])]),s("annotation",{encoding:"application/x-tex"},"a_v^j")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0717em","vertical-align":"-0.247em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8247em"}},[s("span",{style:{top:"-2.453em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"v")])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.247em"}},[s("span")])])])])])])])]),n(" 先做指数变换，目的是为了保证每个边界信息的贡献都能大于0，然后通过归一化为每个特征得到一个o-1之内的权重。最终物品的embedding通过权重进行加权聚合得到，进而优化损失函数：")],-1),q=s("p",null,"​ $$L(v,u,y)=-[ylog( \\sigma (H_v^TZ_u)) + (1-y)log(1 - \\sigma(H_v^TZ_u))]$$",-1),L=s("p",null,[n("y是标签符号，等于1时表示正样本，等于0时表示负样本。"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"H"),s("mi",null,"v")])]),s("annotation",{encoding:"application/x-tex"},"H_v")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.08125em"}},"H"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0813em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"v")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n("表示商品 v 的最终的隐层表示，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"Z"),s("mi",null,"u")])]),s("annotation",{encoding:"application/x-tex"},"Z_u")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"Z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0715em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"u")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),n("表示训练数据中的上下文节点的embedding。")],-1),j=e('<p>以上就是这三个模型主要的区别，下面是EGES的伪代码。</p><div align="center"><img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328155406291.png" style="zoom:80%;"></div><p>其中<strong>WeightedSkipGram</strong>函数为带权重的SkipGram算法。</p><div align="center"><img src="http://ryluo.oss-cn-chengdu.aliyuncs.com/图片image-20220328155533704.png" style="zoom:80%;"></div><h2 id="代码实现" tabindex="-1"><a class="header-anchor" href="#代码实现"><span>代码实现</span></a></h2>',5),B={href:"https://github.com/wangzhegeek/EGES",target:"_blank",rel:"noopener noreferrer"},V=e(`<h3 id="构建物品图-1" tabindex="-1"><a class="header-anchor" href="#构建物品图-1"><span>构建物品图</span></a></h3><p>首先对用户的下单(type=2)行为序列进行session划分，其中30分钟没有产生下一个行为，划分为一个session。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">cnt_session</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> time_cut<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> cut_type<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 商品属性  id  被交互时间   商品种类</span>
    sku_list <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">&#39;sku_id&#39;</span><span class="token punctuation">]</span>
    time_list <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">&#39;action_time&#39;</span><span class="token punctuation">]</span>
    type_list <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">&#39;type&#39;</span><span class="token punctuation">]</span>
    session <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    tmp_session <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> item <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>sku_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 两个商品之间如果被交互的时间大于1小时，划分成不同的session</span>
        <span class="token keyword">if</span> type_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> cut_type <span class="token keyword">or</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sku_list<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span> <span class="token keyword">and</span> \\
            <span class="token punctuation">(</span>time_list<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> time_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>seconds<span class="token operator">/</span><span class="token number">60</span> <span class="token operator">&gt;</span> time_cut<span class="token punctuation">)</span> <span class="token keyword">or</span> i <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sku_list<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            tmp_session<span class="token punctuation">.</span>append<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
            session<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmp_session<span class="token punctuation">)</span>
            tmp_session <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            tmp_session<span class="token punctuation">.</span>append<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
    <span class="token keyword">return</span> session  <span class="token comment"># 返回多个session list</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>获取到所有session list之后(这里不区分具体用户)，对于session长度不超过1的去除(没有意义)。</p><p>接下来就是构建图，主要是先计算所有session中，相邻的物品共现频次(通过字典计算)。然后通过入度节点、出度节点以及权重分别转化成list，通过network来构建有向图。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>node_pair <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 遍历所有session list</span>
<span class="token keyword">for</span> session <span class="token keyword">in</span> session_list_all<span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>session<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将session共现的item存到node_pair中，用于构建item-item图</span>
        <span class="token comment"># 将共现次数所谓边的权重，即node_pair的key为边(src_node,dst_node),value为边的权重(共现次数)</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>session<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> session<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">not</span> <span class="token keyword">in</span> node_pair<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            node_pair<span class="token punctuation">[</span><span class="token punctuation">(</span>session<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> session<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            node_pair<span class="token punctuation">[</span><span class="token punctuation">(</span>session<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> session<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

in_node_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span>node_pair<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
out_node_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span>node_pair<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
weight_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>node_pair<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
graph_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>o<span class="token punctuation">,</span>w<span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span>o<span class="token punctuation">,</span>w <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>in_node_list<span class="token punctuation">,</span>out_node_list<span class="token punctuation">,</span>weight_list<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 通过 network 构建图结构</span>
G <span class="token operator">=</span> nx<span class="token punctuation">.</span>DiGraph<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>add_weighted_edges_from<span class="token punctuation">(</span>graph_list<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="随机游走" tabindex="-1"><a class="header-anchor" href="#随机游走"><span>随机游走</span></a></h3><p>先是基于构建的图进行随机游走，其中p和q是参数，用于控制采样的偏向于DFS还是BFS，其实也就是node2vec。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>walker <span class="token operator">=</span> RandomWalker<span class="token punctuation">(</span>G<span class="token punctuation">,</span> p<span class="token operator">=</span>args<span class="token punctuation">.</span>p<span class="token punctuation">,</span> q<span class="token operator">=</span>args<span class="token punctuation">.</span>q<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Preprocess transition probs...&quot;</span><span class="token punctuation">)</span>
walker<span class="token punctuation">.</span>preprocess_transition_probs<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,9),N={href:"https://blog.csdn.net/haolexiao/article/details/65157026",target:"_blank",rel:"noopener noreferrer"},W=e(`<div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">preprocess_transition_probs</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;预处理随即游走的转移概率&quot;&quot;&quot;</span>
    G <span class="token operator">=</span> self<span class="token punctuation">.</span>G
    alias_nodes <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    <span class="token keyword">for</span> node <span class="token keyword">in</span> G<span class="token punctuation">.</span>nodes<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 获取每个节点与邻居节点边上的权重</span>
        unnormalized_probs <span class="token operator">=</span> <span class="token punctuation">[</span>G<span class="token punctuation">[</span>node<span class="token punctuation">]</span><span class="token punctuation">[</span>nbr<span class="token punctuation">]</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">&#39;weight&#39;</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>   
                                <span class="token keyword">for</span> nbr <span class="token keyword">in</span> G<span class="token punctuation">.</span>neighbors<span class="token punctuation">(</span>node<span class="token punctuation">)</span><span class="token punctuation">]</span>
        norm_const <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>unnormalized_probs<span class="token punctuation">)</span>
         <span class="token comment"># 对每个节点的邻居权重进行归一化</span>
        normalized_probs <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token builtin">float</span><span class="token punctuation">(</span>u_prob<span class="token punctuation">)</span><span class="token operator">/</span>norm_const <span class="token keyword">for</span> u_prob <span class="token keyword">in</span> unnormalized_probs<span class="token punctuation">]</span> 
        <span class="token comment"># 根据权重创建alias表</span>
        alias_nodes<span class="token punctuation">[</span>node<span class="token punctuation">]</span> <span class="token operator">=</span> create_alias_table<span class="token punctuation">(</span>normalized_probs<span class="token punctuation">)</span>
    alias_edges <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    <span class="token keyword">for</span> edge <span class="token keyword">in</span> G<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 获取边的alias</span>
        alias_edges<span class="token punctuation">[</span>edge<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>get_alias_edge<span class="token punctuation">(</span>edge<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edge<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>alias_nodes <span class="token operator">=</span> alias_nodes
    self<span class="token punctuation">.</span>alias_edges <span class="token operator">=</span> alias_edges
    <span class="token keyword">return</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在构建好Alias之后，进行带权重的随机游走。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>session_reproduce <span class="token operator">=</span> walker<span class="token punctuation">.</span>simulate_walks<span class="token punctuation">(</span>num_walks<span class="token operator">=</span>args<span class="token punctuation">.</span>num_walks<span class="token punctuation">,</span> 
            walk_length<span class="token operator">=</span>args<span class="token punctuation">.</span>walk_length<span class="token punctuation">,</span> workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>其中这里的随机游走是根据p和q的值，来选择是使用Deepwalk还是node2vec。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">_simulate_walks</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nodes<span class="token punctuation">,</span> num_walks<span class="token punctuation">,</span> walk_length<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    walks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_walks<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 打乱所有起始节点</span>
        random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>nodes<span class="token punctuation">)</span>
        <span class="token keyword">for</span> v <span class="token keyword">in</span> nodes<span class="token punctuation">:</span>
            <span class="token comment"># 根据p和q选择随机游走或者带权游走</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>p <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">and</span> self<span class="token punctuation">.</span>q <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                walks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deepwalk_walk<span class="token punctuation">(</span>
                    walk_length<span class="token operator">=</span>walk_length<span class="token punctuation">,</span> start_node<span class="token operator">=</span>v<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                walks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>node2vec_walk<span class="token punctuation">(</span>
                    walk_length<span class="token operator">=</span>walk_length<span class="token punctuation">,</span> start_node<span class="token operator">=</span>v<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> walks

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="加载side-information并构造训练正样本" tabindex="-1"><a class="header-anchor" href="#加载side-information并构造训练正样本"><span>加载side information并构造训练正样本</span></a></h3><p>主要是将目前所有的sku和其对应的side infromation进行left join，没有的特征用0补充。然后对所有的特征进行labelEncoder()</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>sku_side_info <span class="token operator">=</span> pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>all_skus<span class="token punctuation">,</span> product_data<span class="token punctuation">,</span> on<span class="token operator">=</span><span class="token string">&#39;sku_id&#39;</span><span class="token punctuation">,</span> how<span class="token operator">=</span><span class="token string">&#39;left&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># 为商品加载side information</span>
<span class="token keyword">for</span> feat <span class="token keyword">in</span> sku_side_info<span class="token punctuation">.</span>columns<span class="token punctuation">:</span>
    <span class="token keyword">if</span> feat <span class="token operator">!=</span> <span class="token string">&#39;sku_id&#39;</span><span class="token punctuation">:</span>
        lbe <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 对side information进行编码</span>
        sku_side_info<span class="token punctuation">[</span>feat<span class="token punctuation">]</span> <span class="token operator">=</span> lbe<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>sku_side_info<span class="token punctuation">[</span>feat<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        sku_side_info<span class="token punctuation">[</span>feat<span class="token punctuation">]</span> <span class="token operator">=</span> sku_lbe<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>sku_side_info<span class="token punctuation">[</span>feat<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通过图中的公式可以知道优化目标是让在一个窗口内的物品尽可能相似，采样若干负样本使之与目标物品不相似。因此需要将一个窗口内的所有物品与目标物品组成pair作为训练正样本。这里不需要采样负样本，负样本是通过tf中的sample softmax方法自动进行采样。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">get_graph_context_all_pairs</span><span class="token punctuation">(</span>walks<span class="token punctuation">,</span> window_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    all_pairs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>walks<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>walks<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 通过窗口的方式采取正样本，具体的是，让随机游走序列的起始item与窗口内的每个item组成正样本对</span>
            <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>i <span class="token operator">-</span> window_size<span class="token punctuation">,</span> i <span class="token operator">+</span> window_size <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> i <span class="token operator">==</span> j <span class="token keyword">or</span> j <span class="token operator">&lt;</span> <span class="token number">0</span> <span class="token keyword">or</span> j <span class="token operator">&gt;=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>walks<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token keyword">continue</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    all_pairs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>walks<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> walks<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>all_pairs<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="eges模型" tabindex="-1"><a class="header-anchor" href="#eges模型"><span>EGES模型</span></a></h4><p>构造完数据之后，在funrec的基础上实现了EGES模型：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">EGES</span><span class="token punctuation">(</span>side_information_columns<span class="token punctuation">,</span> items_columns<span class="token punctuation">,</span> merge_type <span class="token operator">=</span> <span class="token string">&quot;weight&quot;</span><span class="token punctuation">,</span> share_flag<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        l2_reg<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># side_information 所对应的特征</span>
    feature_columns <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>side_information_columns<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 获取输入层，查字典</span>
    feature_encode <span class="token operator">=</span> FeatureEncoder<span class="token punctuation">(</span>feature_columns<span class="token punctuation">,</span>  linear_sparse_feature<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
    <span class="token comment"># 输入的值</span>
    feature_inputs_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>feature_encode<span class="token punctuation">.</span>feature_input_layer_dict<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># item id  获取输入层的值</span>
    items_Map <span class="token operator">=</span> FeatureMap<span class="token punctuation">(</span>items_columns<span class="token punctuation">)</span>
    items_inputs_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>items_Map<span class="token punctuation">.</span>feature_input_layer_dict<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 正样本的id，在softmax中需要传入正样本的id</span>
    label_columns <span class="token operator">=</span> <span class="token punctuation">[</span>DenseFeat<span class="token punctuation">(</span><span class="token string">&#39;label_id&#39;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    label_Map <span class="token operator">=</span> FeatureMap<span class="token punctuation">(</span>label_columns<span class="token punctuation">)</span>
    label_inputs_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>label_Map<span class="token punctuation">.</span>feature_input_layer_dict<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 通过输入的值查side_information的embedding，返回所有side_information的embedding的list</span>
    side_embedding_list <span class="token operator">=</span> process_feature<span class="token punctuation">(</span>side_information_columns<span class="token punctuation">,</span> feature_encode<span class="token punctuation">)</span>
    <span class="token comment"># 拼接  N x num_feature X Dim</span>
    side_embeddings <span class="token operator">=</span> Concatenate<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>side_embedding_list<span class="token punctuation">)</span>

    <span class="token comment"># items_inputs_list[0] 为了查找每个item 用于计算权重的 aplha 向量</span>
    eges_inputs <span class="token operator">=</span> <span class="token punctuation">[</span>side_embeddings<span class="token punctuation">,</span> items_inputs_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

    merge_emb <span class="token operator">=</span> EGESLayer<span class="token punctuation">(</span>items_columns<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>vocabulary_size<span class="token punctuation">,</span> merge_type<span class="token operator">=</span>merge_type<span class="token punctuation">,</span> 
                l2_reg<span class="token operator">=</span>l2_reg<span class="token punctuation">,</span> seed<span class="token operator">=</span>seed<span class="token punctuation">)</span><span class="token punctuation">(</span>eges_inputs<span class="token punctuation">)</span>  <span class="token comment"># B * emb_dim</span>
    
    label_idx <span class="token operator">=</span> label_Map<span class="token punctuation">.</span>feature_input_layer_dict<span class="token punctuation">[</span>label_columns<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>name<span class="token punctuation">]</span>
    softmaxloss_inputs <span class="token operator">=</span> <span class="token punctuation">[</span>merge_emb<span class="token punctuation">,</span>label_idx<span class="token punctuation">]</span>
    
    item_vocabulary_size <span class="token operator">=</span> items_columns<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>vocabulary_size

    all_items_idx <span class="token operator">=</span> EmbeddingIndex<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>item_vocabulary_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    all_items_embeddings <span class="token operator">=</span> feature_encode<span class="token punctuation">.</span>embedding_layers_dict<span class="token punctuation">[</span>side_information_columns<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>name<span class="token punctuation">]</span><span class="token punctuation">(</span>all_items_idx<span class="token punctuation">)</span>

    <span class="token keyword">if</span> share_flag<span class="token punctuation">:</span>
        softmaxloss_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>all_items_embeddings<span class="token punctuation">)</span>
    
    output <span class="token operator">=</span> SampledSoftmaxLayer<span class="token punctuation">(</span>num_items<span class="token operator">=</span>item_vocabulary_size<span class="token punctuation">,</span> share_flage<span class="token operator">=</span>share_flag<span class="token punctuation">,</span>
              emb_dim<span class="token operator">=</span>side_information_columns<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>embedding_dim<span class="token punctuation">,</span>num_sampled<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">(</span>softmaxloss_inputs<span class="token punctuation">)</span>

    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>feature_inputs_list <span class="token operator">+</span> items_inputs_list <span class="token operator">+</span> label_inputs_list<span class="token punctuation">,</span> output<span class="token punctuation">)</span>
    
    model<span class="token punctuation">.</span>__setattr__<span class="token punctuation">(</span><span class="token string">&quot;feature_inputs_list&quot;</span><span class="token punctuation">,</span> feature_inputs_list<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>__setattr__<span class="token punctuation">(</span><span class="token string">&quot;label_inputs_list&quot;</span><span class="token punctuation">,</span> label_inputs_list<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>__setattr__<span class="token punctuation">(</span><span class="token string">&quot;merge_embedding&quot;</span><span class="token punctuation">,</span> merge_emb<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>__setattr__<span class="token punctuation">(</span><span class="token string">&quot;item_embedding&quot;</span><span class="token punctuation">,</span> get_item_embedding<span class="token punctuation">(</span>all_items_embeddings<span class="token punctuation">,</span>                          								items_Map<span class="token punctuation">.</span>feature_input_layer_dict<span class="token punctuation">[</span>items_columns<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>name<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>其中EGESLayer为聚合每个item的多个side information的方法，其中根据merge_type可以选择average-pooling或者weight-pooling</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">EGESLayer</span><span class="token punctuation">(</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>item_nums<span class="token punctuation">,</span> merge_type<span class="token operator">=</span><span class="token string">&quot;weight&quot;</span><span class="token punctuation">,</span>l2_reg<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>EGESLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>item_nums <span class="token operator">=</span> item_nums 
        self<span class="token punctuation">.</span>merge_type <span class="token operator">=</span> merge_type   <span class="token comment">#聚合方式</span>
        self<span class="token punctuation">.</span>l2_reg <span class="token operator">=</span> l2_reg
        self<span class="token punctuation">.</span>seed <span class="token operator">=</span> seed

    <span class="token keyword">def</span> <span class="token function">build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token builtin">len</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">2</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>&#39;\`EGESLayer\` layer should be called \\
                on a <span class="token builtin">list</span> of at least <span class="token number">2</span> inputs&#39;<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>feat_nums <span class="token operator">=</span> input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>merge_type <span class="token operator">==</span> <span class="token string">&quot;weight&quot;</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>alpha_embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>add_weight<span class="token punctuation">(</span>
                                name<span class="token operator">=</span><span class="token string">&#39;alpha_attention&#39;</span><span class="token punctuation">,</span>
                                shape<span class="token operator">=</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>item_nums<span class="token punctuation">,</span> self<span class="token punctuation">.</span>feat_nums<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> 
                                initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>RandomUniform<span class="token punctuation">(</span>minval<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> maxval<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                               seed<span class="token operator">=</span>self<span class="token punctuation">.</span>seed<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                regularizer<span class="token operator">=</span>l2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>l2_reg<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>merge_type <span class="token operator">==</span> <span class="token string">&quot;weight&quot;</span><span class="token punctuation">:</span> 
            stack_embedding <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># (B * num_feate * embedding_size)</span>
            item_input <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>       <span class="token comment"># (B * 1)  </span>
            alpha_embedding <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>embedding_lookup<span class="token punctuation">(</span>self<span class="token punctuation">.</span>alpha_embeddings<span class="token punctuation">,</span> item_input<span class="token punctuation">)</span> <span class="token comment">#(B * 1 * num_feate)</span>
            alpha_emb <span class="token operator">=</span> tf<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>alpha_embedding<span class="token punctuation">)</span> 
            alpha_i_sum <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>alpha_emb<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> 
            merge_embedding <span class="token operator">=</span> tf<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>alpha_emb<span class="token punctuation">,</span> stack_embedding<span class="token punctuation">)</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> alpha_i_sum
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            stack_embedding <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># (B * num_feate * embedding_size)</span>
            merge_embedding <span class="token operator">=</span> tf<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>alpha_emb<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># (B * embedding_size)</span>
        
        <span class="token keyword">return</span> merge_embedding

    <span class="token keyword">def</span> <span class="token function">compute_output_shape</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> input_shape

    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        config <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;merge_type&quot;</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>merge_type<span class="token punctuation">,</span> <span class="token string">&quot;seed&quot;</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>seed<span class="token punctuation">}</span>
        base_config <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span>EGESLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        base_config<span class="token punctuation">.</span>update<span class="token punctuation">(</span>config<span class="token punctuation">)</span>
        <span class="token keyword">return</span> base_config

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>至此已经从原理到代码详细的介绍了关于EGES的内容。</p><h2 id="参考" tabindex="-1"><a class="header-anchor" href="#参考"><span>参考</span></a></h2>`,17),D={href:"https://arxiv.org/abs/1803.02349",target:"_blank",rel:"noopener noreferrer"},I={href:"https://zhuanlan.zhihu.com/p/64200072",target:"_blank",rel:"noopener noreferrer"},$={href:"https://blog.csdn.net/qq_27075943/article/details/106244434",target:"_blank",rel:"noopener noreferrer"},H={href:"https://www.jianshu.com/p/229b686535f1",target:"_blank",rel:"noopener noreferrer"};function F(R,C){const a=l("ExternalLinkIcon");return o(),i("div",null,[u,r,m,k,d,v,g,h,b,_,y,f,w,x,z,E,G,M,S,q,L,j,s("p",null,[n("下面我们简单的来看一下模型代码的实现，参考的内容在"),s("a",B,[n("这里"),t(a)]),n("，其中实验使用的是jd 2019年比赛中提供的数据。")]),V,s("p",null,[n("对于采样的具体过程，是根据边的归一化权重作为采样概率进行采样。其中关于如何通过AliasSampling来实现概率采样的可以"),s("a",N,[n("参考"),t(a)]),n("，具体的是先通过计算create_alias_table，然后根据边上两个节点的alias计算边的alias。其中可以看到这里计算alias_table是根据边的归一化权重。")]),W,s("p",null,[s("a",D,[n("Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba"),t(a)])]),s("p",null,[s("a",I,[n("深度学习中不得不学的Graph Embedding方法"),t(a)])]),s("p",null,[s("a",$,[n("【Embedding】EGES：阿里在图嵌入领域中的探索"),t(a)])]),s("p",null,[s("a",H,[n("推荐系统遇上深度学习(四十六)-阿里电商推荐中亿级商品的embedding策略"),t(a)])])])}const A=p(c,[["render",F],["__file","eges.html.vue"]]),K=JSON.parse('{"path":"/rcmd/ch02/ch2.3/eges.html","title":"阿里：EGES模型","lang":"zh-CN","frontmatter":{"date":"2024-06-20T00:00:00.000Z","title":"阿里：EGES模型","shortTitle":"EGES模型","author":"Genhiy","order":1,"category":["推荐系统"],"tag":["无标签"],"feed":false,"seo":false,"head":[]},"headers":[{"level":2,"title":"动机","slug":"动机","link":"#动机","children":[]},{"level":2,"title":"思路","slug":"思路","link":"#思路","children":[]},{"level":2,"title":"模型结构与原理","slug":"模型结构与原理","link":"#模型结构与原理","children":[{"level":3,"title":"构建物品图","slug":"构建物品图","link":"#构建物品图","children":[]},{"level":3,"title":"图嵌入(BGE)","slug":"图嵌入-bge","link":"#图嵌入-bge","children":[]},{"level":3,"title":"基于side information的图嵌入（GES）","slug":"基于side-information的图嵌入-ges","link":"#基于side-information的图嵌入-ges","children":[]},{"level":3,"title":"增强型EGS（EGES）","slug":"增强型egs-eges","link":"#增强型egs-eges","children":[]}]},{"level":2,"title":"代码实现","slug":"代码实现","link":"#代码实现","children":[{"level":3,"title":"构建物品图","slug":"构建物品图-1","link":"#构建物品图-1","children":[]},{"level":3,"title":"随机游走","slug":"随机游走","link":"#随机游走","children":[]},{"level":3,"title":"加载side information并构造训练正样本","slug":"加载side-information并构造训练正样本","link":"#加载side-information并构造训练正样本","children":[]}]},{"level":2,"title":"参考","slug":"参考","link":"#参考","children":[]}],"git":{},"readingTime":{"minutes":15.62,"words":4685},"filePathRelative":"rcmd/ch02/ch2.3/eges.md","localizedDate":"2024年6月20日"}');export{A as comp,K as data};
