import{_ as p}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as o,o as c,c as l,a as n,d as a,b as t,e as s}from"./app-SD3SAAIy.js";const i={},r=s('<h2 id="vscode相关" tabindex="-1"><a class="header-anchor" href="#vscode相关"><span>vscode相关</span></a></h2><h3 id="无代码补全" tabindex="-1"><a class="header-anchor" href="#无代码补全"><span>无代码补全</span></a></h3><p>一般是python编辑器的问题，注意是否激活了python环境。如果也无法激活python环境，就检查一下python的几个扩展是否存在问题，特别是pylance，尤其是其可能未【启用】。</p><p>再记录一个很好用的vscode扩展：IntelliCode Completions，IntelliCode Completions根据当前上下文预测一整行代码。预测显示为灰色文本在光标的右侧。此扩展支持Python、JavaScript和TypeScript。</p><h2 id="nan-and-inf" tabindex="-1"><a class="header-anchor" href="#nan-and-inf"><span>NaN and Inf</span></a></h2>',5),d={href:"https://blog.csdn.net/danmeng8068/article/details/120061823",target:"_blank",rel:"noopener noreferrer"},u=s(`<p>这种问题常见于网络训练中，较难处理，其中一种可能性是从单卡迁移到多卡时没有降学习率。</p><h3 id="debug" tabindex="-1"><a class="header-anchor" href="#debug"><span>debug</span></a></h3><p>但是还有很多可能性，建议在可能出现nan和inf的代码段中加入以下语句，print出每个循环变量的均值、最大值、最小值、nan的变量个数。注：代码中的tensor为需要查看的变量，请根据自己的变量名进行替换。<code>torch.distributed.barrier()</code>是在等待多进程同步。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>barrier<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;mean:{},max:{},min:{},nan:{}&#39;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="半精度越界" tabindex="-1"><a class="header-anchor" href="#半精度越界"><span>半精度越界</span></a></h3><p>在计算attention的过程中可能会出现最值超过半精度最值65504的问题，需找到inf出现的位置，然后使用：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">from</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>amp <span class="token keyword">import</span> autocast
<span class="token keyword">with</span> autocast<span class="token punctuation">(</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">:</span>
    ……
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>注意：autocast的囊括范围可以大一些，因为其表示在这个范围内，均使用float32进行计算。<code>autocast(dtype=torch.float32)</code>结束在数据大小回到65504范围内之后即可。</p><h3 id="未知的load影响" tabindex="-1"><a class="header-anchor" href="#未知的load影响"><span>未知的load影响</span></a></h3><p>问题：在程序里加了下面一行代码后，出现Nan，查找发现是一个毫不相关的transformer层报的Nan，而且经对比debug，加不加这行代码，这个transformer层的输入、权重均相同，但就是一个报Nan一个正常……</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>sd <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>embed_tokens_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&quot;state_dict&quot;</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>原因：未知，推测是load时产生了一些影响。</p><p>解决方案：在Class类外的其他地方load这个ckpt，然后把需要的数据传入进来，而不是把路径传入进来再load。</p><h2 id="cpu、gpu利用率问题" tabindex="-1"><a class="header-anchor" href="#cpu、gpu利用率问题"><span>CPU、GPU利用率问题</span></a></h2><p>在深度学习模型训练过程中，在服务器端或者本地pc端，输入nvidia-smi来观察显卡的GPU内存占用率（Memory-Usage），显卡的GPU利用率（GPU-util），然后采用top来查看CPU的线程数（PID数）和利用率（%CPU）。往往会发现很多问题，比如，GPU内存占用率低，显卡利用率低，CPU百分比低等等。</p>`,15),h={href:"https://gitcode.csdn.net/6628b34a9ab37021bfb0b731.html",target:"_blank",rel:"noopener noreferrer"},k=s(`<h3 id="gpu内存占用率问题" tabindex="-1"><a class="header-anchor" href="#gpu内存占用率问题"><span>GPU内存占用率问题</span></a></h3><p>这往往是由于模型的大小以及batch size的大小，来影响这个指标。当你发下你的GPU占用率很小的时候，比如40%，70%，等等。此时，如果你的网络结构已经固定，此时只需要改变batch size的大小，就可以尽量利用完整个GPU的内存。GPU的内存占用率主要是模型的大小，包括网络的宽度，深度，参数量，中间每一层的缓存，都会在内存中开辟空间来进行保存，所以模型本身会占用很大一部分内存。其次是batch size的大小，也会占用影响内存占用率。batch size设置为128，与设置为256相比，内存占用率是接近于2倍关系。当你batch size设置为128，占用率为40%的话，设置为256时，此时模型的占用率约等于80%，偏差不大。所以在模型结构固定的情况下，尽量将batch size设置大，充分利用GPU的内存。（GPU会很快的算完你给进去的数据，主要瓶颈在CPU的数据吞吐量上面。）</p><h3 id="gpu利用率问题" tabindex="-1"><a class="header-anchor" href="#gpu利用率问题"><span>GPU利用率问题</span></a></h3><p>这个是Volatile GPU-Util表示，当没有设置好CPU的线程数时，这个参数是在反复的跳动的，0%，20%，70%，95%，0%。这样停息1-2 秒然后又重复起来。其实是GPU在等待数据从CPU传输过来，当从总线传输到GPU之后，GPU逐渐起计算来，利用率会突然升高，但是GPU的算力很强大，0.5秒就基本能处理完数据，所以利用率接下来又会降下去，等待下一个batch的传入。因此，这个GPU利用率瓶颈在内存带宽和内存介质上以及CPU的性能上面。最好当然就是换更好的四代或者更强大的内存条，配合更好的CPU。</p><p>另外的一个方法是，在PyTorch这个框架里面，数据加载Dataloader上做更改和优化，包括num_workers（线程数），pin_memory，会提升速度。解决好数据传输的带宽瓶颈和GPU的运算效率低的问题。在TensorFlow下面，也有这个加载数据的设置。</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">,</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>为了提高利用率，首先要将num_workers（线程数）设置得体，4,8,16是几个常选的几个参数。本人测试过，将num_workers设置的非常大，例如，24，32,等，其效率反而降低，因为模型需要将数据平均分配到几个子线程去进行预处理，分发等数据操作，设高了反而影响效率。当然，线程数设置为1，是单个CPU来进行数据的预处理和传输给GPU，效率也会低。其次，当你的服务器或者电脑的内存较大，性能较好的时候，建议打开pin_memory打开，就省掉了将数据从CPU传入到缓存RAM里面，再给传输到GPU上；为True时是直接映射到GPU的相关内存块上，省掉了一点数据传输时间。</p><h3 id="cpu的利用率问题" tabindex="-1"><a class="header-anchor" href="#cpu的利用率问题"><span>CPU的利用率问题</span></a></h3><p>很多人在模型训练过程中，不只是关注GPU的各种性能参数，往往还需要查看CPU处理的怎么样，利用的好不好。这一点至关重要。但是对于CPU，不能一味追求超高的占用率。如图所示，对于14339这个程序来说，其CPU占用率为2349%（我的服务器是32核的，所以最高为3200%）。这表明用了24核CPU来加载数据和做预处理和后处理等。其实主要的CPU花在加载传输数据上。此时，来测量数据加载的时间发现，即使CPU利用率如此之高，其实际数据加载时间是设置恰当的DataLoader的20倍以上，也就是说这种方法来加载数据慢20倍。当DataLoader的num_workers=0时，或者不设置这个参数，会出现这个情况。</p><h2 id="库函数" tabindex="-1"><a class="header-anchor" href="#库函数"><span>库函数</span></a></h2><h3 id="bdb-bdbquit" tabindex="-1"><a class="header-anchor" href="#bdb-bdbquit"><span>bdb.bdbquit</span></a></h3><p>问题：调试时加入pdb调试代码，定位到断点之后程序直接中断并报错bdb.bdbquit。</p><p>解决办法：不能在有多个进程的情况下调试代码，只用单卡，设置workers_per_gpu=0即可正常使用pdb！</p><h3 id="tqdm" tabindex="-1"><a class="header-anchor" href="#tqdm"><span>tqdm</span></a></h3><p>问题：<code>&#39;module&#39; object is not callable</code>。</p><p>原因：讲真这种报错很迷惑人，这个错并不是因为module不能调用，而是……import错了……应该<code>from tqdm import tqdm</code>，而不是<code>import tqdm</code>，讲真，这个包也是有问题，为什么非要这样import……</p><h2 id="其他" tabindex="-1"><a class="header-anchor" href="#其他"><span>其他</span></a></h2><h3 id="get-unexpected-keyword-argument" tabindex="-1"><a class="header-anchor" href="#get-unexpected-keyword-argument"><span>get unexpected keyword argument</span></a></h3><p>需要定位报错的函数，看看是参数多写了还是函数少写了。</p><p>冷门错误：在sh文件设置第三方库Deepspeed环境变量时文件目录设置错了，但是并不会报找不到文件的错误，因为Deepspeed自己就是一个库，会直接用python中的库，而由于这个库被自定义修改了，所以就报了错。</p><h3 id="unicode-utf-8" tabindex="-1"><a class="header-anchor" href="#unicode-utf-8"><span>Unicode utf-8</span></a></h3><p><code>UnicodeDecodeError: &#39;utf-8&#39; codec can&#39;t decode byte 0xc3 in position 2: invalid continuation byte</code></p><p>原因：代码的注释中用了中文，对，注释中也不行，删掉就没问题了……</p><h3 id="训练结果差" tabindex="-1"><a class="header-anchor" href="#训练结果差"><span>训练结果差</span></a></h3><p>训练集准确率过低，无法拟合，跟随机一摸一样，调模型没效果。</p><p>原因：使用了0.1的学习率，对这个任务而言太高了，改成0.01后问题解决。以后调试模型阶段建议从小的学习率(1e-2~1e-4)开始。</p><h3 id="库函数管理" tabindex="-1"><a class="header-anchor" href="#库函数管理"><span>库函数管理</span></a></h3><p>问题：ModuleNotFoundError: No module named xxx</p><p>解决方法：大概率是import 路径有问题，先用os包查看报错代码的时候对应的绝对路径是什么：<code>print(os.path.abspath(&quot;.&quot;))</code>，然后，确定好从绝对路径到需要import的代码的相对位置即可：<code>import sys</code>;<code>sys.path.append(&#39;到报错代码的相对路径&#39;)</code>。</p><h3 id="多进程" tabindex="-1"><a class="header-anchor" href="#多进程"><span>多进程</span></a></h3><p>问题：在dataloader里用了CUDA后，就会出现“RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the &#39;spawn&#39; start method”的问题。</p><p>解决方案：在dataloader里设置num_workers=0，比如：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="ddp" tabindex="-1"><a class="header-anchor" href="#ddp"><span>DDP</span></a></h3><p>问题：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token punctuation">[</span>W socket<span class="token punctuation">.</span>cpp<span class="token punctuation">:</span><span class="token number">436</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>c10d<span class="token punctuation">]</span> The server socket has failed to bind to <span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token number">29500</span> <span class="token punctuation">(</span>errno<span class="token punctuation">:</span> <span class="token number">98</span> <span class="token operator">-</span> Address already <span class="token keyword">in</span> use<span class="token punctuation">)</span><span class="token punctuation">.</span>
<span class="token punctuation">[</span>W socket<span class="token punctuation">.</span>cpp<span class="token punctuation">:</span><span class="token number">436</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>c10d<span class="token punctuation">]</span> The server socket has failed to bind to <span class="token number">0.0</span><span class="token number">.0</span><span class="token number">.0</span><span class="token punctuation">:</span><span class="token number">29500</span> <span class="token punctuation">(</span>errno<span class="token punctuation">:</span> <span class="token number">98</span> <span class="token operator">-</span> Address already <span class="token keyword">in</span> use<span class="token punctuation">)</span><span class="token punctuation">.</span>
<span class="token punctuation">[</span>E socket<span class="token punctuation">.</span>cpp<span class="token punctuation">:</span><span class="token number">472</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>c10d<span class="token punctuation">]</span> The server socket has failed to listen on <span class="token builtin">any</span> local network address<span class="token punctuation">.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>解决方案：有些进程占用了端口，使用<code>ps aux</code>查看进程，然后把冲突的进程<code>kill -9</code>关掉。</p><h3 id="git-status" tabindex="-1"><a class="header-anchor" href="#git-status"><span>Git status</span></a></h3><p>问题：把一批 git 项目从一台设备拷到另一台设备之后，未对文件做任何修改，但是进入到项目的根目录下，执行git status却发现所有的文件状态都是modified。</p><p>执行<code>git diff --summary</code>发现大多都是<code>mode change 100644 =&gt; 100755</code>，原来是拷贝文件的过程中，文件的权限被自动修改了，权限值由644变成了755. 这种情况如何处理呢？</p><p>解决方案：关闭 git 的 filemode：</p><ul><li>全局关闭：<code>git config --global core.filemode false</code></li><li>单项目关闭：<code>git config core.filemode false</code></li></ul><h3 id="run-py-error" tabindex="-1"><a class="header-anchor" href="#run-py-error"><span>run.py error</span></a></h3><p>问题：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>run<span class="token punctuation">.</span>py<span class="token punctuation">:</span> error<span class="token punctuation">:</span> the following arguments are required<span class="token punctuation">:</span> training_script<span class="token punctuation">,</span> training_script_args
bash<span class="token punctuation">:</span> line <span class="token number">1</span><span class="token punctuation">:</span> <span class="token operator">/</span>mnt<span class="token operator">/</span>iag<span class="token operator">/</span>user<span class="token operator">/</span>daiyiheng<span class="token operator">/</span>model<span class="token operator">/</span>easyllm<span class="token operator">/</span>llm<span class="token operator">/</span>runners<span class="token operator">/</span>hf_runner<span class="token punctuation">.</span>py<span class="token punctuation">:</span> Permission denied
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>原因：在sh文件中，代码是这样写的：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code>export LAUNCHER<span class="token operator">=</span>&quot;OMP_NUM_THREADS<span class="token operator">=</span><span class="token number">8</span> python <span class="token operator">-</span>m torch<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>run \\
    <span class="token operator">-</span><span class="token operator">-</span>nproc_per_node $GPUS_PER_NODE \\
    <span class="token operator">-</span><span class="token operator">-</span>nnodes $NNODES
    &quot; 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>注意倒数第二行，少了一个<code>\\</code>，这种问题真的好烦啊，而且这种问题的报错往往不能反映实际发生的问题。</p>`,48);function m(b,g){const e=o("ExternalLinkIcon");return c(),l("div",null,[r,n("p",null,[a("参考：CSDN："),n("a",d,[a("Pytorch定位NaN"),t(e)])]),u,n("blockquote",null,[n("p",null,[a("参考："),n("a",h,[a("深度学习PyTorch，TensorFlow中GPU利用率较低，CPU利用率很低，且模型训练速度很慢的问题总结与分析"),t(e)])])]),k])}const f=p(i,[["render",m],["__file","error.html.vue"]]),P=JSON.parse('{"path":"/zsk/tech/python/error.html","title":"报错及处理方案合集","lang":"zh-CN","frontmatter":{"date":"2024-04-24T00:00:00.000Z","title":"报错及处理方案合集","author":"Genhiy","order":7,"category":["AI"],"tag":["debug"],"description":"vscode相关 无代码补全 一般是python编辑器的问题，注意是否激活了python环境。如果也无法激活python环境，就检查一下python的几个扩展是否存在问题，特别是pylance，尤其是其可能未【启用】。 再记录一个很好用的vscode扩展：IntelliCode Completions，IntelliCode Completions根据...","head":[["meta",{"property":"og:url","content":"https://github.com/Genhiy/Genhiy.github.io/zsk/tech/python/error.html"}],["meta",{"property":"og:site_name","content":"Genhiy"}],["meta",{"property":"og:title","content":"报错及处理方案合集"}],["meta",{"property":"og:description","content":"vscode相关 无代码补全 一般是python编辑器的问题，注意是否激活了python环境。如果也无法激活python环境，就检查一下python的几个扩展是否存在问题，特别是pylance，尤其是其可能未【启用】。 再记录一个很好用的vscode扩展：IntelliCode Completions，IntelliCode Completions根据..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"Genhiy"}],["meta",{"property":"article:tag","content":"debug"}],["meta",{"property":"article:published_time","content":"2024-04-24T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"报错及处理方案合集\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-04-24T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Genhiy\\"}]}"]]},"headers":[{"level":2,"title":"vscode相关","slug":"vscode相关","link":"#vscode相关","children":[{"level":3,"title":"无代码补全","slug":"无代码补全","link":"#无代码补全","children":[]}]},{"level":2,"title":"NaN and Inf","slug":"nan-and-inf","link":"#nan-and-inf","children":[{"level":3,"title":"debug","slug":"debug","link":"#debug","children":[]},{"level":3,"title":"半精度越界","slug":"半精度越界","link":"#半精度越界","children":[]},{"level":3,"title":"未知的load影响","slug":"未知的load影响","link":"#未知的load影响","children":[]}]},{"level":2,"title":"CPU、GPU利用率问题","slug":"cpu、gpu利用率问题","link":"#cpu、gpu利用率问题","children":[{"level":3,"title":"GPU内存占用率问题","slug":"gpu内存占用率问题","link":"#gpu内存占用率问题","children":[]},{"level":3,"title":"GPU利用率问题","slug":"gpu利用率问题","link":"#gpu利用率问题","children":[]},{"level":3,"title":"CPU的利用率问题","slug":"cpu的利用率问题","link":"#cpu的利用率问题","children":[]}]},{"level":2,"title":"库函数","slug":"库函数","link":"#库函数","children":[{"level":3,"title":"bdb.bdbquit","slug":"bdb-bdbquit","link":"#bdb-bdbquit","children":[]},{"level":3,"title":"tqdm","slug":"tqdm","link":"#tqdm","children":[]}]},{"level":2,"title":"其他","slug":"其他","link":"#其他","children":[{"level":3,"title":"get unexpected keyword argument","slug":"get-unexpected-keyword-argument","link":"#get-unexpected-keyword-argument","children":[]},{"level":3,"title":"Unicode utf-8","slug":"unicode-utf-8","link":"#unicode-utf-8","children":[]},{"level":3,"title":"训练结果差","slug":"训练结果差","link":"#训练结果差","children":[]},{"level":3,"title":"库函数管理","slug":"库函数管理","link":"#库函数管理","children":[]},{"level":3,"title":"多进程","slug":"多进程","link":"#多进程","children":[]},{"level":3,"title":"DDP","slug":"ddp","link":"#ddp","children":[]},{"level":3,"title":"Git status","slug":"git-status","link":"#git-status","children":[]},{"level":3,"title":"run.py error","slug":"run-py-error","link":"#run-py-error","children":[]}]}],"git":{},"readingTime":{"minutes":8.56,"words":2569},"filePathRelative":"zsk/tech/python/error.md","localizedDate":"2024年4月24日","excerpt":"<h2>vscode相关</h2>\\n<h3>无代码补全</h3>\\n<p>一般是python编辑器的问题，注意是否激活了python环境。如果也无法激活python环境，就检查一下python的几个扩展是否存在问题，特别是pylance，尤其是其可能未【启用】。</p>\\n<p>再记录一个很好用的vscode扩展：IntelliCode Completions，IntelliCode Completions根据当前上下文预测一整行代码。预测显示为灰色文本在光标的右侧。此扩展支持Python、JavaScript和TypeScript。</p>\\n<h2>NaN and Inf</h2>\\n<p>参考：CSDN：<a href=\\"https://blog.csdn.net/danmeng8068/article/details/120061823\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Pytorch定位NaN</a></p>","autoDesc":true}');export{f as comp,P as data};
