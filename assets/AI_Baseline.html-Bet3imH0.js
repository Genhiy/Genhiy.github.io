import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as t,c as a,e as n}from"./app-SD3SAAIy.js";const o={},p=n('<h1 id="cnn" tabindex="-1"><a class="header-anchor" href="#cnn"><span>CNN</span></a></h1><p>CNN的核心功能是特征提取与选择，本质上是一种输入到输出的映射。</p><h2 id="池化" tabindex="-1"><a class="header-anchor" href="#池化"><span>池化</span></a></h2><p>池化过程在一般卷积过程后。池化（pooling） 的本质，其实就是采样。Pooling 对于输入的 Feature Map，选择某种方式对其进行降维压缩，以加快运算速度。</p><p>池化有两种，最大池化和平均池化。【池化层没有参数、池化层没有参数、池化层没有参数】 （重要的事情说三遍）</p><p>池化的作用：</p><ul><li>保留主要特征的同时减少参数和计算量，防止过拟合。</li><li>invariance(不变性)，这种不变性包括translation(平移)，rotation(旋转)，scale(尺度)。</li></ul><p>Pooling 层说到底还是一个特征选择，信息过滤的过程。也就是说我们损失了一部分信息，这是一个和计算性能的一个妥协，随着运算速度的不断提高，我认为这个妥协会越来越小。现在有些网络都开始少用或者不用pooling层了。</p><h3 id="池化层的反向传播" tabindex="-1"><a class="header-anchor" href="#池化层的反向传播"><span>池化层的反向传播</span></a></h3><p>对于平均池化，其前向传播是取某特征区域的平均值进行输出，这个区域的每一个神经元都是有参与前向传播了的，因此，在反向传播时，框架需要将梯度平均分配给每一个神经元再进行反向传播。比如四个像素分别为2 3 5 6，平均值为4，那么反向传播时以每个像素点均为4进行反向传播。</p><p>对于最大池化，其前向传播是取某特征区域的最大值进行输出，这个区域仅有最大值神经元参与了前向传播，因此，在反向传播时，框架仅需要将该区域的梯度直接分配到最大值神经元即可，其他神经元的梯度被分配为0且是被舍弃不参与反向传播的，但如何确认最大值神经元，这个还得框架在进行前向传播时记录下最大值神经元的Max ID位置，这是最大池化与平均池化差异的地方。</p><h3 id="其他池化方法" tabindex="-1"><a class="header-anchor" href="#其他池化方法"><span>其他池化方法</span></a></h3><p><strong>引入概率，将确定性变为随机：</strong></p><p>随机池化：先将方格中的元素同时除以它们的和sum，得到概率矩阵，然后按照概率随机选中方格，pooling得到的值就是方格位置的值。</p><p><strong>引入超参数，均衡两种池化方法：</strong></p><p>混合池化：用随机过程代替了常规的确定性池化操作，在模型训练期间随机采用最大池化和平均池化方法。</p><p>幂平均池化：引入超参数，当p=1时，使用平均池化，p趋于无穷时使用最大池化。</p><p><strong>组合两种池化方法：</strong></p><p>组合池化：同时利用最大值池化与均值池化两种的优势而引申的一种池化策略。常见组合策略有两种：Cat与Add。常常被当做分类任务的一个trick，其作用就是丰富特征层，maxpool更关注重要的局部特征，而average pooling更关注全局特征。</p><p><strong>自适应池化方法：</strong></p><p>如何对输入自适应也是一个很重要的研究问题。</p><p>自适应平均池化（Adaptive Average Pooling）：一种对输入进行自适应调整大小的池化操作。在传统的平均池化中，我们需要指定池化操作的输出尺寸，而自适应平均池化则可以根据输入的大小自动决定输出的尺寸。</p><p>自适应最大池化是一种池化方法，其目的是在不改变输入形状的情况下，通过自适应地更改池化大小在整个输入中找到最大值。</p><p><strong>引入可微函数：</strong></p><p>软池化（Soft Pooling）：基于softmax加权的方法来保留输入的基本属性，同时放大更大强度的特征激活。其将各位置的softmax值作为权重，加权求和。与maxpooling不同，softpool是可微的，所以网络在反向传播过程中为每个输入获得一个梯度，这有利于提高训练效果。</p>',25),i=[p];function r(l,s){return t(),a("div",null,i)}const g=e(o,[["render",r],["__file","AI_Baseline.html.vue"]]),d=JSON.parse('{"path":"/zsk/ai/ai_base/AI_Baseline.html","title":"深挖AI基础模型","lang":"zh-CN","frontmatter":{"title":"深挖AI基础模型","date":"2024-04-18T00:00:00.000Z","author":"Genhiy","order":3,"category":["AI"],"tag":["池化"],"description":"CNN CNN的核心功能是特征提取与选择，本质上是一种输入到输出的映射。 池化 池化过程在一般卷积过程后。池化（pooling） 的本质，其实就是采样。Pooling 对于输入的 Feature Map，选择某种方式对其进行降维压缩，以加快运算速度。 池化有两种，最大池化和平均池化。【池化层没有参数、池化层没有参数、池化层没有参数】 （重要的事情说三遍...","head":[["meta",{"property":"og:url","content":"https://github.com/Genhiy/Genhiy.github.io/zsk/ai/ai_base/AI_Baseline.html"}],["meta",{"property":"og:site_name","content":"Genhiy"}],["meta",{"property":"og:title","content":"深挖AI基础模型"}],["meta",{"property":"og:description","content":"CNN CNN的核心功能是特征提取与选择，本质上是一种输入到输出的映射。 池化 池化过程在一般卷积过程后。池化（pooling） 的本质，其实就是采样。Pooling 对于输入的 Feature Map，选择某种方式对其进行降维压缩，以加快运算速度。 池化有两种，最大池化和平均池化。【池化层没有参数、池化层没有参数、池化层没有参数】 （重要的事情说三遍..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"Genhiy"}],["meta",{"property":"article:tag","content":"池化"}],["meta",{"property":"article:published_time","content":"2024-04-18T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"深挖AI基础模型\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-04-18T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Genhiy\\"}]}"]]},"headers":[{"level":2,"title":"池化","slug":"池化","link":"#池化","children":[{"level":3,"title":"池化层的反向传播","slug":"池化层的反向传播","link":"#池化层的反向传播","children":[]},{"level":3,"title":"其他池化方法","slug":"其他池化方法","link":"#其他池化方法","children":[]}]}],"git":{},"readingTime":{"minutes":3.63,"words":1088},"filePathRelative":"zsk/ai/ai_base/AI_Baseline.md","localizedDate":"2024年4月18日","excerpt":"\\n<p>CNN的核心功能是特征提取与选择，本质上是一种输入到输出的映射。</p>\\n<h2>池化</h2>\\n<p>池化过程在一般卷积过程后。池化（pooling） 的本质，其实就是采样。Pooling 对于输入的 Feature Map，选择某种方式对其进行降维压缩，以加快运算速度。</p>\\n<p>池化有两种，最大池化和平均池化。【池化层没有参数、池化层没有参数、池化层没有参数】 （重要的事情说三遍）</p>\\n<p>池化的作用：</p>\\n<ul>\\n<li>保留主要特征的同时减少参数和计算量，防止过拟合。</li>\\n<li>invariance(不变性)，这种不变性包括translation(平移)，rotation(旋转)，scale(尺度)。</li>\\n</ul>","autoDesc":true}');export{g as comp,d as data};
